\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{rabiner1990tut}
\citation{vogel1996hmm}
\citation{kuhn1994hmmlm,huang2011thesis}
\citation{bengio2003nlm}
\citation{zaremba2014lstm}
\citation{merity2017awdlstm}
\citation{buys2018hmm}
\citation{krakovna2016hmm}
\citation{tran2016hmm}
\citation{han2017dependency}
\citation{wiseman2018hsmm}
\citation{kim2019cpcfg}
\citation{petrov2006splitmerge,huang2011thesis}
\citation{huang2011thesis}
\citation{ladner1980prefix}
\citation{bradbury2016qrnn}
\citation{dedieu2019learning}
\newlabel{param}{{2}{2}{Background: HMMs}{equation.3.2}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:trellis}{{1}{2}{HMM search space after applying emission sparsity constraints and the state dropout method. \relax }{figure.caption.1}{}}
\citation{kim2019cpcfg}
\citation{brown1992,liang2005brown}
\newlabel{eqn:sparse_marginalization}{{3}{3}{Blocked Emissions}{equation.4.3}{}}
\newlabel{fig:algo}{{1}{3}{VL-HMM Training \relax }{algorithm.1}{}}
\newlabel{eqn:state_dropout}{{5}{3}{Dropout as State Reduction}{equation.4.5}{}}
\newlabel{sec:experiments}{{5}{3}{HMM Language models}{section.5}{}}
\citation{ptb}
\citation{wikitext}
\citation{mikolov-2011}
\citation{kenlm}
\citation{mikolov2012rnn}
\citation{buys2018hmm}
\citation{buys2018hmm}
\citation{mikolov2012rnn}
\citation{mikolov2012rnn}
\citation{zaremba2014lstm}
\citation{zaremba2014lstm}
\citation{merity2017awdlstm}
\citation{buys2018hmm}
\citation{buys2018hmm}
\citation{merity2017awdlstm}
\citation{mos}
\citation{awddoc}
\newlabel{tbl:states-ablation}{{2}{4}{Perplexities on the \texttt {Penn Treebank} dataset as a function of the state size $|\mcZ |$. We hold the emission constraints fixed using 128 Brown clusters, and state dropout at 0.5. \relax }{figure.caption.9}{}}
\newlabel{tbl:ptb-ppl}{{1}{5}{Perplexities on the \texttt {Penn Treebank} dataset. The bottom section shows results for models with comparable computational cost. In particular, we compare models that have the same asymptotic inference cost: linear in the length of a sequence and quadratic in the hidden dimension. This is $h=256$ for the FF model and LSTM and $|\mcZ | = 256$ for the HMM. \relax }{table.caption.6}{}}
\newlabel{tbl:wt2-ppl}{{2}{5}{Single model perplexities on the \texttt {Wikitext-2} dataset. The bottom shows results for the models with similar computation cost, using the same hyperparameters applied to \texttt {Penn Treebank}. \relax }{table.caption.7}{}}
\bibstyle{acl_natbib}
\bibdata{anthology,emnlp2020}
\bibcite{bengio2003nlm}{{1}{2003}{{Bengio et~al.}}{{Bengio, Ducharme, Vincent, and Janvin}}}
\bibcite{bradbury2016qrnn}{{2}{2016}{{Bradbury et~al.}}{{Bradbury, Merity, Xiong, and Socher}}}
\bibcite{brown1992}{{3}{1992}{{Brown et~al.}}{{Brown, deSouza, Mercer, Pietra, and Lai}}}
\bibcite{buys2018hmm}{{4}{2018}{{Buys et~al.}}{{Buys, Bisk, and Choi}}}
\bibcite{dedieu2019learning}{{5}{2019}{{Dedieu et~al.}}{{Dedieu, Gothoskar, Swingle, Lehrach, L\IeC {\'a}zaro-Gredilla, and George}}}
\bibcite{han2017dependency}{{6}{2017}{{Han et~al.}}{{Han, Jiang, and Tu}}}
\bibcite{kenlm}{{7}{2013}{{Heafield et~al.}}{{Heafield, Pouzyrevsky, Clark, and Koehn}}}
\bibcite{huang2011thesis}{{8}{2011}{{Huang}}{{}}}
\bibcite{kim2019cpcfg}{{9}{2019}{{Kim et~al.}}{{Kim, Dyer, and Rush}}}
\bibcite{krakovna2016hmm}{{10}{2016}{{Krakovna and Doshi-Velez}}{{}}}
\bibcite{kuhn1994hmmlm}{{11}{1994}{{Kuhn et~al.}}{{Kuhn, Niemann, and Schukat-Talamazzini}}}
\bibcite{ladner1980prefix}{{12}{1980}{{Ladner and Fischer}}{{}}}
\bibcite{liang2005brown}{{13}{2005}{{Liang}}{{}}}
\bibcite{ptb}{{14}{1993}{{Marcus et~al.}}{{Marcus, Santorini, and Marcinkiewicz}}}
\bibcite{merity2017awdlstm}{{15}{2017}{{Merity et~al.}}{{Merity, Keskar, and Socher}}}
\bibcite{wikitext}{{16}{2016}{{Merity et~al.}}{{Merity, Xiong, Bradbury, and Socher}}}
\bibcite{mikolov2012rnn}{{17}{2012}{{{Mikolov} and {Zweig}}}{{}}}
\bibcite{mikolov-2011}{{18}{2011}{{Mikolov et~al.}}{{Mikolov, Deoras, Kombrink, Burget, and Cernock\IeC {\'y}}}}
\bibcite{petrov2006splitmerge}{{19}{2006}{{Petrov et~al.}}{{Petrov, Barrett, Thibaux, and Klein}}}
\bibcite{rabiner1990tut}{{20}{1990}{{Rabiner}}{{}}}
\bibcite{awddoc}{{21}{2018}{{Takase et~al.}}{{Takase, Suzuki, and Nagata}}}
\newlabel{tbl:constraint-ablation}{{3}{6}{Perplexities on the \texttt {Penn Treebank} dataset. We ablate the effect of the number of Brown clusters, examine whether there may be a drop in performance due to the emission sparsity constraint, and compare the Brown cluster constraint to a uniform baseline. All models have 0.5 state dropout, except for the 1k state HMMs, which have no dropout. We use $m$ to indicate the number of clusters. \relax }{table.caption.10}{}}
\bibcite{tran2016hmm}{{22}{2016}{{Tran et~al.}}{{Tran, Bisk, Vaswani, Marcu, and Knight}}}
\bibcite{vogel1996hmm}{{23}{1996}{{Vogel et~al.}}{{Vogel, Ney, and Tillmann}}}
\bibcite{wiseman2018hsmm}{{24}{2018}{{Wiseman et~al.}}{{Wiseman, Shieber, and Rush}}}
\bibcite{mos}{{25}{2017}{{Yang et~al.}}{{Yang, Dai, Salakhutdinov, and Cohen}}}
\bibcite{zaremba2014lstm}{{26}{2014}{{Zaremba et~al.}}{{Zaremba, Sutskever, and Vinyals}}}
\newlabel{tbl:dropout-param-ablation}{{4}{7}{We report perplexities on the \texttt {Penn Treebank} dataset for a 16k state HMM with 0.5 state dropout and 128 Brown clusters, and ablate dropout and the neural parameterization one at a time. \relax }{table.caption.13}{}}
\newlabel{sec:hyperparams}{{A}{7}{Hyperparameters}{appendix.A}{}}
\newlabel{sec:supplemental}{{B}{7}{Supplemental Material}{appendix.B}{}}
